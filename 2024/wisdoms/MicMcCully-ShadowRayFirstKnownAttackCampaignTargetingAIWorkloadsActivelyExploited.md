# SUMMARY
Mick McCully from Olo Security discusses "Shadow Ray," a vulnerability in AI's open-source infrastructure.

# IDEAS:
- Shadow vulnerabilities exist without public awareness and are often only known to maintainers.
- Vulnerabilities may be disputed, complicating the identification and mitigation of security risks.
- Developers rarely read all documentation, leading to potential security oversights in open-source libraries.
- Many popular libraries contain warnings about malicious code execution, often overlooked by users.
- Default configurations in libraries can expose users to security risks if not properly configured.
- AI infrastructure is rapidly adopted, increasing the risk of unaddressed vulnerabilities in real-world applications.
- Many AI systems are built on open-source components, heightening the potential for security flaws.
- Attackers target AI due to its access to vast amounts of sensitive data and resources.
- Misconfigured AI tools can lead to significant exposure and exploitation of sensitive information.
- Shadow vulnerabilities present unique challenges since they lack corresponding CVEs for identification.
- Reverse shells and crypto miners are common exploitation techniques observed in compromised AI systems.
- The speed of AI adoption often outpaces security considerations, creating vulnerabilities in production environments.
- Educational efforts are needed to raise awareness about the risks associated with AI and open-source use.
- Organizations must prioritize understanding and addressing potential risks from disputed CVEs in their systems.
- A runtime solution may be necessary to identify vulnerabilities in open-source components without published CVEs.
- Responsible disclosure is crucial for increasing awareness of shadow vulnerabilities within the community.

# INSIGHTS:
- Awareness of shadow vulnerabilities is critical for organizations using open-source AI components.
- The rapid adoption of AI technologies necessitates stronger security measures and practices.
- Misconfigurations in AI tools can lead to severe data exposure if not properly managed.
- Education on potential risks should be a priority for businesses leveraging AI applications.
- The presence of disputed CVEs indicates the need for vigilance in security practices.
- Shadow vulnerabilities can be exploited without clear indicators, complicating detection efforts.
- Security teams must adapt to the evolving landscape of AI and its inherent risks.
- Organizations should treat AI systems as any other application regarding security diligence.
- Understanding documentation is essential to avoid misconfigurations leading to vulnerabilities.
- Collaboration between developers and security professionals is necessary for effective risk management.

# QUOTES:
- "Shadow vulnerabilities are vulnerabilities that exist that you may not be aware of."
- "If a tree falls in the forest, does anyone know about it?"
- "If you're not aware of the security implications, it makes it very difficult to understand."
- "The flexibility of the library exposes you to these types of attacks."
- "AI has access to tons and tons of data, a huge gold mine for attackers."
- "The technology is being adopted very very fast, increasing the risks."
- "You’re only as strong as your weakest link."
- "One of the first largest wild exploitation of an AI engine."
- "Sometimes a runtime solution is the only way to identify these vulnerabilities."
- "The default settings sometimes expose you to these attacks without you being aware."
- "The attackers are always trying to stay two steps ahead."
- "Understanding documentation is essential to avoid misconfigurations leading to vulnerabilities."
- "It’s insecure by design; it needs to be shared more easily."
- "This is why we had an exclusive; it was a significant discovery."
- "Education on potential risks should be a priority for businesses leveraging AI applications."
- "The presence of disputed CVEs indicates the need for vigilance in security practices."

# HABITS:
- Regularly review and read documentation for all open-source libraries used in projects.
- Engage in responsible disclosure processes when vulnerabilities are discovered.
- Collaborate with security professionals to improve awareness of potential risks in AI systems.
- Monitor for and address any disputed CVEs in utilized software components.
- Conduct security audits on AI configurations to prevent unintended exposure of sensitive data.
- Stay updated on emerging threats and vulnerabilities within the open-source community.
- Implement runtime solutions to identify anomalous behavior in application libraries.
- Encourage teams to prioritize security considerations during rapid AI adoption phases.
- Use sandboxing techniques to analyze behavior of open-source libraries before deployment.
- Share knowledge of discovered vulnerabilities with peers to promote awareness and security.

# FACTS:
- Shadow vulnerabilities are often only known to maintainers, leading to security oversights.
- Many popular open-source libraries contain warnings about potential malicious code execution.
- Default configurations in libraries can expose users to security risks if not addressed.
- AI infrastructure is rapidly adopted, increasing the risk of vulnerabilities in production.
- Reverse shells and crypto miners are common exploitation techniques in compromised AI systems.
- The speed of AI adoption outpaces security considerations, creating vulnerabilities.
- Disputed CVEs indicate potential risks that may not be publicly recognized.
- Misconfigured AI tools can lead to significant exposure of sensitive information.
- Open-source components in AI systems heighten the potential for security flaws.
- Attackers target AI systems due to their access to vast amounts of sensitive data.

# REFERENCES:
- Olo Security's blog for detailed disclosures on shadow vulnerabilities.
- The Ray AI engine as a focus of the shadow vulnerability discussion.
- Documentation from popular libraries like pickle, numpy, and pandas.
- Responsible disclosure processes discussed for addressing vulnerabilities.
- Techniques for runtime solutions and sandboxing for identifying vulnerabilities.

# ONE-SENTENCE TAKEAWAY
Awareness of shadow vulnerabilities in AI and open-source components is crucial for effective security management.

# RECOMMENDATIONS:
- Regularly educate teams on the security implications of using open-source software in projects.
- Monitor and address vulnerabilities in AI infrastructure promptly to mitigate risks.
- Establish a culture of responsible disclosure to enhance security awareness across the organization.
- Implement proactive security measures to detect and address shadow vulnerabilities in AI systems.
- Encourage teams to engage with documentation to better understand potential risks and configurations.
- Utilize runtime solutions to detect anomalous behavior in open-source libraries effectively.
- Promote collaboration between developers and security teams for comprehensive risk management.
- Share findings and discoveries of vulnerabilities within the community to raise awareness.
- Prioritize security in the development and deployment of AI applications to prevent exploitation.
- Stay informed about emerging threats and vulnerabilities in the evolving landscape of AI.